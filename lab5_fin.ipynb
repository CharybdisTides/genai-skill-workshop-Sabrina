{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "qZMPf_KP2Eb0",
      "metadata": {
        "id": "qZMPf_KP2Eb0"
      },
      "source": [
        "# LAB 5\n",
        "\n",
        "* Make a rag or bq database and embed the documents\n",
        "* Make api tool calling for weather and alaska city location\n",
        "---\n",
        "* Test and verify you can send a request and get a weather report or faq on the alaskan department of snow.\n",
        "* Evaluate groundedness?\n",
        "---\n",
        "* Prompt filtering and response validation implemented into the solution (Keep to security guidlines) Kinda tied in to above testing\n",
        "---\n",
        "* Log conversations... Somewhere...\n",
        "---\n",
        "* Deploy onto web app\n",
        "(utalize ai and quick assist to help with front end)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YEQnHtvGLgZI",
      "metadata": {
        "id": "YEQnHtvGLgZI"
      },
      "source": [
        "## SET UP\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "-w9wk2F0EYNR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-w9wk2F0EYNR",
        "outputId": "045340e2-a277-4f9d-b801-ce385e91362c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.1/278.1 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m121.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.2/788.2 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colabsqlviz 0.2.7 requires protobuf<7.0.0,>=6.31.1, but you have protobuf 5.29.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.46.0)\n",
            "Collecting google-genai\n",
            "  Downloading google_genai-1.53.0-py3-none-any.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.14.1->google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.11.10)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
            "Downloading google_genai-1.53.0-py3-none-any.whl (262 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.0/262.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-genai\n",
            "  Attempting uninstall: google-genai\n",
            "    Found existing installation: google-genai 1.46.0\n",
            "    Uninstalling google-genai-1.46.0:\n",
            "      Successfully uninstalled google-genai-1.46.0\n",
            "Successfully installed google-genai-1.53.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "e89ad255def44c51861537314d3ddbe1",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting google-cloud-modelarmor\n",
            "  Downloading google_cloud_modelarmor-0.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-modelarmor) (2.28.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-modelarmor) (2.38.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-modelarmor) (1.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-modelarmor) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-modelarmor) (5.29.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-modelarmor) (1.71.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-modelarmor) (2.32.4)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-modelarmor) (1.67.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-modelarmor) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-modelarmor) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-modelarmor) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-modelarmor) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-modelarmor) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-modelarmor) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-modelarmor) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-modelarmor) (2025.10.5)\n",
            "Downloading google_cloud_modelarmor-0.3.0-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.2/134.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-cloud-modelarmor\n",
            "Successfully installed google-cloud-modelarmor-0.3.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "1748a1c5cee848cea1f1a3d948ef414c",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "ambiguous option: --upgrad (--upgrade, --upgrade-strategy?)\n",
            "Collecting requests==2.31.0\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests==2.31.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests==2.31.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests==2.31.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests==2.31.0) (2025.10.5)\n",
            "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: requests\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.31.0 which is incompatible.\n",
            "google-adk 1.17.0 requires requests<3.0.0,>=2.32.4, but you have requests 2.31.0 which is incompatible.\n",
            "datasets 4.0.0 requires requests>=2.32.2, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed requests-2.31.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "ea53b428ba4042699ab688141dae3399",
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "! pip install --upgrade --quiet google-cloud-aiplatform google-cloud-aiplatform[evaluation]\n",
        "! pip install --quiet ipytest\n",
        "! pip install --upgrade google-genai\n",
        "! pip install google-cloud-modelarmor\n",
        "! pip install --upgrad google-cloud-bigquery\n",
        "!pip install requests==2.31.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OXrgwLIu3Zji",
      "metadata": {
        "id": "OXrgwLIu3Zji"
      },
      "source": [
        "\n",
        "Copy over data\n",
        "```\n",
        "gsutil cp -r gs://labs.roitraining.com/alaska-dept-of-snow ~/\n",
        "```\n",
        "\n",
        "Create bq data files\n",
        "```\n",
        "export mydataset=\"alaska_dept_faq_db\"\n",
        "export mytable=\"faqs_table\"\n",
        "```\n",
        "```\n",
        "bq mk $mydataset\n",
        "bq load \\\n",
        "  --source_format=CSV \\\n",
        "  --skip_leading_rows=0 \\\n",
        "  $mydataset.$mytable \\\n",
        "  ~/alaska-dept-of-snow/alaska-dept-of-snow-faqs.csv \\\n",
        "  question:STRING,answer:STRING\n",
        "\n",
        "bq ls $mydataset\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qJnXlw9aLpHB",
      "metadata": {
        "id": "qJnXlw9aLpHB"
      },
      "source": [
        "## Restart Session\n",
        "\n",
        "You have set up env and datasets, you may need to restart before procededing with the rest of the code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "h_Hb9QAuFTTU",
      "metadata": {
        "id": "h_Hb9QAuFTTU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from IPython.display import display, Markdown, HTML\n",
        "\n",
        "import requests\n",
        "\n",
        "import pytest\n",
        "import ipytest\n",
        "ipytest.autoconfig()\n",
        "\n",
        "from vertexai.evaluation import (\n",
        "    MetricPromptTemplateExamples,\n",
        "    EvalTask,\n",
        ")\n",
        "\n",
        "from google import genai\n",
        "from google.genai.types import Tool, ToolCodeExecution, GenerateContentConfig, SafetySetting, Part, FunctionDeclaration\n",
        "from google.cloud import modelarmor_v1\n",
        "from google.api_core.client_options import ClientOptions\n",
        "\n",
        "import datetime\n",
        "from google.cloud import bigquery\n",
        "\n",
        "\n",
        "import google.cloud.logging\n",
        "import logging\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2YmyN5gtfGaMLXfZysIx26c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YmyN5gtfGaMLXfZysIx26c5",
        "outputId": "6380c0a9-bebc-4719-9f32-09fe8fc03a99",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "qwiklabs-gcp-02-47840be12dd1.alaska_dept_faq_db.sql_connected_model\n",
            "qwiklabs-gcp-02-47840be12dd1.alaska_dept_faq_db.faqs_table\n",
            "qwiklabs-gcp-02-47840be12dd1.alaska_dept_faq_db.withEmbedding\n"
          ]
        }
      ],
      "source": [
        "project_id = !gcloud config get project\n",
        "project_id = project_id[0]\n",
        "location = \"us-central1\"\n",
        "MY_API_KEY=\"\"\n",
        "\n",
        "model = \"gemini-2.5-flash\"\n",
        "\n",
        "\n",
        "mydataset = \"alaska_dept_faq_db\"#!echo $mydataset\n",
        "mytable = f\"\"\"{project_id}.{mydataset}.faqs_table\"\"\" #!echo $project_id.$mydataset.$mytable\n",
        "\n",
        "mymodel = f\"\"\"{project_id}.{mydataset}.sql_connected_model\"\"\"\n",
        "embededTable = f\"\"\"{project_id}.{mydataset}.withEmbedding\"\"\"\n",
        "\n",
        "print(mymodel)\n",
        "print(mytable)\n",
        "print(embededTable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "bX8W6wpCOWNB",
      "metadata": {
        "id": "bX8W6wpCOWNB"
      },
      "outputs": [],
      "source": [
        "# init genai sdk client\n",
        "genai_client = genai.Client(\n",
        "    vertexai=True,\n",
        "    project=project_id,\n",
        "    location=location\n",
        ")\n",
        "\n",
        "# init big query client\n",
        "bq_client = bigquery.Client(project=project_id)\n",
        "datasets = list(bq_client.list_datasets())\n",
        "\n",
        "\n",
        "# init the Cloud Logging client\n",
        "from google.cloud import logging as cloud_logging\n",
        "log_client = google.cloud.logging.Client()\n",
        "log_client.setup_logging()\n",
        "\n",
        "log_handler = log_client.get_default_handler()\n",
        "\n",
        "cloud_logger = logging.getLogger(\"cloudLogger\")\n",
        "cloud_logger.setLevel(logging.INFO)\n",
        "cloud_logger.addHandler(log_handler)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rCshh_8SZS-L",
      "metadata": {
        "id": "rCshh_8SZS-L"
      },
      "source": [
        "## MODEL ARMOR\n",
        "in the navigation menu\n",
        "Security > ModelArmor\n",
        "create a template and put the template path in the id below.\n",
        "\n",
        "name == ADS_model_armor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "nM-HIi6dWDm7",
      "metadata": {
        "id": "nM-HIi6dWDm7"
      },
      "outputs": [],
      "source": [
        "armor_id = f\"projects/{project_id}/locations/{location}/templates/ADS_model_armor\"\n",
        "\n",
        "\n",
        "armoredClient = modelarmor_v1.ModelArmorClient(\n",
        "    transport=\"rest\",\n",
        "    client_options=ClientOptions(\n",
        "        api_endpoint=f\"modelarmor.{location}.rep.googleapis.com\"\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wa2PO3ZN6VpB",
      "metadata": {
        "id": "wa2PO3ZN6VpB"
      },
      "source": [
        "## Making Tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "O-QDDAdgQCWk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-QDDAdgQCWk",
        "outputId": "e8266f2f-87b8-4368-aa77-13ef7f146ef2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CREATE OR REPLACE MODEL `qwiklabs-gcp-02-47840be12dd1.alaska_dept_faq_db.sql_connected_model`\n",
            "REMOTE WITH CONNECTION DEFAULT\n",
            "OPTIONS (ENDPOINT = 'text-embedding-005');\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "QueryJob<project=qwiklabs-gcp-02-47840be12dd1, location=US, id=f3004b7f-ecbd-49d1-95d9-7456768f8707>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Makes a model that is connected to BigQuerry...\n",
        "makeModel = f\"\"\"CREATE OR REPLACE MODEL `{mymodel}`\n",
        "REMOTE WITH CONNECTION DEFAULT\n",
        "OPTIONS (ENDPOINT = 'text-embedding-005');\"\"\"\n",
        "print(makeModel)\n",
        "bq_client.query(makeModel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "lXcXOzDcUENZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXcXOzDcUENZ",
        "outputId": "9baa65fc-206a-43c5-b001-240ce38de317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<google.cloud.bigquery.table._EmptyRowIterator object at 0x7f1aa4837830>\n",
            "QueryJob<project=qwiklabs-gcp-02-47840be12dd1, location=US, id=3988fef0-fa93-4677-9230-f11ec5ab5ec2>\n"
          ]
        }
      ],
      "source": [
        "## Makes a Table that has been embeded\n",
        "embedding = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{embededTable}` AS\n",
        "  SELECT *\n",
        "  FROM ML.GENERATE_EMBEDDING(\n",
        "  MODEL `{mymodel}`,\n",
        "  (\n",
        "    SELECT question, answer,\tCONCAT(question, answer) AS content\n",
        "    FROM `{mytable}`)\n",
        "  );\n",
        "\"\"\"\n",
        "query_job = bq_client.query(embedding)\n",
        "\n",
        "results = query_job.result()\n",
        "print(results)\n",
        "print(query_job)\n",
        "if results == None:\n",
        "  print(\"Big Query Client isn't working\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "Pl9xH_Tl1mhW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl9xH_Tl1mhW",
        "outputId": "ccdf7235-d829-48ec-fb45-df7012ebf6c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<google.cloud.bigquery.table._EmptyRowIterator object at 0x7f1aa44c24e0>\n",
            "QueryJob<project=qwiklabs-gcp-02-47840be12dd1, location=US, id=a237f092-3020-444b-8ee4-65c2adb4a3df>\n"
          ]
        }
      ],
      "source": [
        "# ## Makes a Table for the chat Logs\n",
        "# chat_log_table_id = f\"{project_id}.{mydataset}.chat_logs\"\n",
        "\n",
        "# logging_table = f\"\"\"\n",
        "# CREATE TABLE IF NOT EXISTS `{chat_log_table_id}` (\n",
        "#   timestamp TIMESTAMP NOT NULL,\n",
        "#   user_prompt STRING NOT NULL,\n",
        "#   model_response STRING NOT NULL\n",
        "# );\n",
        "# \"\"\"\n",
        "# query_job = bq_client.query(logging_table)\n",
        "\n",
        "# results = query_job.result()\n",
        "# print(results)\n",
        "# print(query_job)\n",
        "# if results == None:\n",
        "#   print(\"Big Query Client isn't working\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7EBxoBJ69uK9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EBxoBJ69uK9",
        "outputId": "054908c9-ee47-4993-e49d-a6077b467714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     tableId      Type    Labels   Time Partitioning   Clustered Fields  \n",
            " --------------- ------- -------- ------------------- ------------------ \n",
            "  chat_logs       TABLE                                                  \n",
            "  faqs_table      TABLE                                                  \n",
            "  withEmbedding   TABLE                                                  \n"
          ]
        }
      ],
      "source": [
        "!bq ls {mydataset}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fuMMl4od3qLf",
      "metadata": {
        "id": "fuMMl4od3qLf"
      },
      "source": [
        "## Functions\n",
        "\n",
        "* https://www.weather.gov/documentation/services-web-api\n",
        "* https://console.cloud.google.com/google/maps-apis/home;onboard=true?project=qwiklabs-gcp-03-29c3da30d8ab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5kkKyKiD0_LU",
      "metadata": {
        "id": "5kkKyKiD0_LU"
      },
      "source": [
        "### Sanatize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "K5BjRjaQVAh1",
      "metadata": {
        "id": "K5BjRjaQVAh1"
      },
      "outputs": [],
      "source": [
        "def sanatize_text(prompt):\n",
        "  # Returns True (1) if is passes the sanatization test\n",
        "  # Returns False (0) if it fails and needs to be disregaurded.\n",
        "  user_prompt_data = modelarmor_v1.types.DataItem(text=prompt)\n",
        "\n",
        "  ## breaks\n",
        "  request = modelarmor_v1.SanitizeUserPromptRequest(\n",
        "    name= armor_id,\n",
        "    user_prompt_data=user_prompt_data,\n",
        "  )\n",
        "  response = armoredClient.sanitize_user_prompt(request=request)\n",
        "  #print(response)\n",
        "  #print(str(response.sanitization_result.filter_match_state))\n",
        "  if response.sanitization_result.filter_match_state == 1:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "def sanitize_response(response_text):\n",
        "  # If response_text has no value, then return an error message\n",
        "  if not response_text:\n",
        "    return \"An unknown error has occured.\"\n",
        "\n",
        "  model_response_data = modelarmor_v1.DataItem(text = response_text)\n",
        "  request = modelarmor_v1.SanitizeModelResponseRequest(\n",
        "      name= armor_id,\n",
        "      model_response_data=model_response_data,\n",
        "      )\n",
        "\n",
        "  response = genai_client.sanitize_model_response(request=request)\n",
        "\n",
        "  # Return the Sanitized text if sensitive data was found.\n",
        "  # If no sensitive data was found, just return the response text passed to the function.\n",
        "  if str(response.sanitization_result.filter_match_state) == \"FilterMatchState.MATCH_FOUND\":\n",
        "    sanitized_text = response.sanitization_result.filter_results[\"sdp\"].sdp_filter_result.deidentify_result.data.text\n",
        "    return sanitized_text\n",
        "  else:\n",
        "    # There was no invalid data, so just return what was sent in\n",
        "    return response_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p21DsNJl1CVQ",
      "metadata": {
        "id": "p21DsNJl1CVQ"
      },
      "source": [
        "### TOOL Function Decleration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "R00v3Cm5WNeC",
      "metadata": {
        "id": "R00v3Cm5WNeC"
      },
      "outputs": [],
      "source": [
        "rag_query_info = FunctionDeclaration(\n",
        "    name=\"rag_query\",\n",
        "    description=\"VectorSearch's user prompt to faq database and returns related content.\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"query\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The user's question or prompt to search for in the FAQ database.\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"query\"]\n",
        "    },\n",
        ")\n",
        "\n",
        "get_forecast_info = FunctionDeclaration(\n",
        "    name=\"get_forcast\",\n",
        "    description=\"Given a city name returns a json about upcoming weather patterns\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"city\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"A city in Alaska\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"city\"]\n",
        "    },\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8UpThB_AUp3_",
      "metadata": {
        "id": "8UpThB_AUp3_"
      },
      "source": [
        "### API Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "l0vvH1mV3rz5",
      "metadata": {
        "id": "l0vvH1mV3rz5"
      },
      "outputs": [],
      "source": [
        "# Takes user input and return context from faq doc using rag\n",
        "def rag_query(user_input):\n",
        "\n",
        "  ## Embed user query and find closest neighbors\n",
        "  instructions = (f\"\"\"\n",
        "    SELECT base.answer,\tbase.question\n",
        "    FROM VECTOR_SEARCH(\n",
        "      TABLE `{embededTable}`,\n",
        "      'ml_generate_embedding_result',\n",
        "      (\n",
        "        SELECT ml_generate_embedding_result, content AS query\n",
        "        FROM ML.GENERATE_EMBEDDING(\n",
        "          MODEL `{mymodel}`,\n",
        "            (SELECT '{user_input}' AS content))\n",
        "      ),\n",
        "    top_k => 5,\"\"\" +\n",
        "    \"\"\"options => '{\"fraction_lists_to_search\": 0.01}'\n",
        "    )\n",
        "    \"\"\"\n",
        "  )\n",
        "  #print(instructions)\n",
        "\n",
        "  ## Query BQ\n",
        "  res = bq_client.query(instructions)\n",
        "  if res == None:\n",
        "    print(\":( sorry no luck\")\n",
        "\n",
        "  ## Build context\n",
        "  context = \"\"\n",
        "  for row in res:\n",
        "    context += row['question']+ \"\\n\"+ row['answer'] + (\"-\" * 20)\n",
        "\n",
        "  return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "iRX2stxLiZKS",
      "metadata": {
        "id": "iRX2stxLiZKS"
      },
      "outputs": [],
      "source": [
        "# Using geolocation api from gcp and the api key MY_API_KEY\n",
        "# return lat long given a city in alaska\n",
        "# if the city does not exsist return none.\n",
        "def get_latlong(city):\n",
        "  state = \"alaska\"\n",
        "  address = f\"{city}, {state}\"\n",
        "\n",
        "  geocode_url = f\"https://maps.googleapis.com/maps/api/geocode/json?address={address}&key={MY_API_KEY}\"\n",
        "\n",
        "  try:\n",
        "    response = requests.get(geocode_url)\n",
        "    response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "    data = response.json()\n",
        "\n",
        "    if data['status'] == 'OK' and data['results']:\n",
        "      location = data['results'][0]['geometry']['location']\n",
        "      lat = location['lat']\n",
        "      long = location['lng']\n",
        "      return lat, long\n",
        "    else:\n",
        "      print(f\"Could not find coordinates for {city}, {state}. Status: {data['status']}\")\n",
        "      return None, None\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error making Geocoding API call: {e}\")\n",
        "    return None, None\n",
        "\n",
        "# helper function\n",
        "# Given lat long coordinates return metadata wfo and x,y coordinate for forcast api call\n",
        "# https://api.weather.gov/points/{lat},{long}\n",
        "def get_points_metadata(lat, long):\n",
        "  url = f\"https://api.weather.gov/points/{lat},{long}\"\n",
        "\n",
        "  try:\n",
        "    response = requests.get(url, headers={'User-Agent': 'Google Colab Weather App (your_email@example.com)'})\n",
        "    response.raise_for_status()  # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "    data = response.json()\n",
        "\n",
        "    # Extracting the required information\n",
        "    properties = data.get('properties', {})\n",
        "    wfo = properties.get('gridId')\n",
        "    x = properties.get('gridX')\n",
        "    y = properties.get('gridY')\n",
        "\n",
        "    if wfo and x is not None and y is not None:\n",
        "      return wfo, x, y\n",
        "    else:\n",
        "      print(f\"Could not find WFO, gridX, or gridY for {lat},{long}. Response properties: {properties}\")\n",
        "      return None, None, None\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error making NWS /points API call: {e}\")\n",
        "    return None, None, None\n",
        "  y=\"\"\n",
        "  url = f\"https://api.weather.gov/points/{lat},{long}\"\n",
        "\n",
        "  return wfo, x, y\n",
        "\n",
        "\n",
        "# Given a city return a forcast json\n",
        "# It is a list of items for different times\n",
        "# \"name\" = tonight\n",
        "# \"shortForecast\": \"Slight Chance Light Rain\",\n",
        "# \"detailedForecast\": \"A slight chance of rain. Cloudy, with a high near 34. Northeast wind ...\n",
        "def get_forecast(city):\n",
        "\n",
        "  lat_anchorage, long_anchorage = get_latlong(city)\n",
        "  print (f\"{lat_anchorage} {long_anchorage}\")\n",
        "\n",
        "  wfo,grid_x,grid_y = get_points_metadata(lat=lat_anchorage, long=long_anchorage)\n",
        "\n",
        "  # Construct the forecast URL\n",
        "  forecast_url = f\"https://api.weather.gov/gridpoints/{wfo}/{grid_x},{grid_y}/forecast\"\n",
        "\n",
        "  # Make the API call to get the forecast\n",
        "  try:\n",
        "    # NWS API recommends a User-Agent header\n",
        "    response = requests.get(forecast_url, headers={'User-Agent': 'Google Colab Weather App (your_email@example.com)'})\n",
        "    response.raise_for_status()  # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "    forecast_data = response.json()\n",
        "    return forecast_data['properties']['periods']\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error making NWS forecast API call: {e}\")\n",
        "    return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LGNdm1yL3E7v",
      "metadata": {
        "id": "LGNdm1yL3E7v"
      },
      "source": [
        "### Finalize Tool calling and Configurations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "m8B4AFpP3EC9",
      "metadata": {
        "id": "m8B4AFpP3EC9"
      },
      "outputs": [],
      "source": [
        "\n",
        "rag_tool = Tool(functionDeclarations=[rag_query_info])\n",
        "forecast_tool = Tool(functionDeclarations=[get_forecast_info])\n",
        "\n",
        "sys_msg = \"\"\"\n",
        "* You are the chat bot for Alaska's Department of Snow (ADS).\n",
        "* You are friendly, but breif.\n",
        "* You answer questions related to the department and weather in Alaska, if a\n",
        "client asks'a question about something else remind them that you are \"only the\n",
        "agent for ADS, and can not speak for topics outside of that.\n",
        "* Refrence Rag tool when answering FAQ about the department, there may be\n",
        "information related to the topic that can be mentioned as well.\n",
        "\"\"\"\n",
        "\n",
        "config = GenerateContentConfig(\n",
        "    tools=[rag_tool, forecast_tool],\n",
        "    system_instruction=[sys_msg]\n",
        "    )\n",
        "\n",
        "\n",
        "chat = genai_client.chats.create(\n",
        "   model=model,\n",
        "   config=config\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4YrlfC4HLZZA",
      "metadata": {
        "id": "4YrlfC4HLZZA"
      },
      "source": [
        "## GENERATE response function\n",
        "\n",
        "I don't know why, but sometimes it doesn't run the first time? But I havn't been able to trigger it consistantly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "D8uj9oXGHOmd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8uj9oXGHOmd",
        "outputId": "f6dae5a4-5744-40c9-c2eb-88f59fc9af55"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:cloudLogger:User Message: how much training do snowplow drivers receive?\n",
            "INFO:httpx:HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/qwiklabs-gcp-02-47840be12dd1/locations/us-central1/publishers/google/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n",
            "INFO:cloudLogger:AI Response: ADS snowplow drivers receive specialized training in winter driving techniques, equipment maintenance, and safety protocols for extreme cold environments.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ADS snowplow drivers receive specialized training in winter driving techniques, equipment maintenance, and safety protocols for extreme cold environments.\n"
          ]
        }
      ],
      "source": [
        "# function calling isn't automatic. This function checks if the AI determins there needs to be\n",
        "# a tool call made and makes it.\n",
        "def generate(user_prompt) -> str:\n",
        "\n",
        "  # Check if User input is safe\n",
        "  if sanatize_text(user_prompt) == False:\n",
        "    return \"I'm sorry this prompt has flagged the security system, please ask something else.\"\n",
        "  else:\n",
        "    # log user input if safe\n",
        "    cloud_logger.info(f\"User Message: {user_prompt}\")\n",
        "\n",
        "  response = chat.send_message(user_prompt)\n",
        "\n",
        "  # Do we need to make a function\n",
        "  if response.candidates[0].content.parts[0].function_call:\n",
        "    function_name = response.candidates[0].content.parts[0].function_call.name\n",
        "    args = response.candidates[0].content.parts[0].function_call.args\n",
        "\n",
        "    # Which function do we call?\n",
        "    if function_name == \"rag_query\":\n",
        "      context = rag_query(args[\"query\"])\n",
        "    elif function_name == \"get_forcast\":\n",
        "      context = get_forecast(args[\"city\"])\n",
        "    else:\n",
        "      context = \"Unknown function call\"\n",
        "\n",
        "    # Get final prompt with proper context\n",
        "    final_prompt = f\"{user_prompt}\\nContext: {context}\"\n",
        "    response = chat.send_message(final_prompt)\n",
        "\n",
        "    # Sanatize AI response\n",
        "    response = sanitize_response(response)\n",
        "\n",
        "  # Log safe AI response and return\n",
        "  cloud_logger.info(f\"AI Response: {response.text}\")\n",
        "  return response.text\n",
        "\n",
        "print(generate(\"how much training do snowplow drivers receive?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yrRd3e42ssT3",
      "metadata": {
        "id": "yrRd3e42ssT3"
      },
      "source": [
        "## TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "9HoATQqYsukO",
      "metadata": {
        "id": "9HoATQqYsukO"
      },
      "outputs": [],
      "source": [
        "def test_geo_api():\n",
        "  cities = [\"jenue\", \"Anchorage\", \"Fairbanks\"]\n",
        "\n",
        "  lat, long = get_latlong(cities[0])\n",
        "  assert lat == 58.30049329999999\n",
        "  assert long == -134.4201306\n",
        "\n",
        "  lat, long = get_latlong(cities[1])\n",
        "  assert lat == 61.2175758\n",
        "  assert long == -149.8996785\n",
        "\n",
        "  lat, long = get_latlong(cities[2])\n",
        "  assert lat == 64.8400511\n",
        "  assert long == -147.7199756\n",
        "\n",
        "  for city in cities:\n",
        "    lat, long = get_latlong(city)\n",
        "    print(f\"{city}: {lat}, {long}\")\n",
        "\n",
        "def test_geo_bad():\n",
        "  # 63.588753, -154.4930619 <-- this is the bad location\n",
        "  # because I auto the state to alaska if the city is bad it just defaults here.\n",
        "  # It's just how their api is\n",
        "\n",
        "  cities = [\"Madaline\", 123, \"ladada!\"]\n",
        "  for city in cities:\n",
        "    lat, long = get_latlong(city)\n",
        "    assert lat == 63.588753\n",
        "    assert long == -154.4930619\n",
        "\n",
        "def test_get_points_metadata():\n",
        "  city = \"Anchorage\"\n",
        "  lat, long = get_latlong(city)\n",
        "  w,x,y = get_points_metadata(lat=lat, long=long)\n",
        "\n",
        "  print(f\"{w} {x} {y}\")\n",
        "\n",
        "  lat, long = 61.2175758, -149.8996785\n",
        "  w2,x2,y2 = get_points_metadata(lat=lat, long=long)\n",
        "  assert w == w2\n",
        "  assert x == x2\n",
        "  assert y == y2\n",
        "\n",
        "def test_get_points_metadata_bad():\n",
        "  lat, long = 63.588753, -154.4930619\n",
        "  w,x,y = get_points_metadata(lat=lat, long=long)\n",
        "  assert w == \"AFG\"\n",
        "  print(f\"{w} {x} {y}\")\n",
        "\n",
        "def test_get_forecast():\n",
        "  city_name = \"Anchorage\"\n",
        "  forecast = get_forecast(city_name)\n",
        "  print(forecast[0]['name'])\n",
        "  print(forecast[0]['shortForecast'])\n",
        "  print(forecast[0]['detailedForecast'])\n",
        "  assert forecast is not None\n",
        "\n",
        "## RAG test\n",
        "def test_rag_query():\n",
        "  user_input = \"What are the requirements for a snow machine license?\"\n",
        "  context = rag_query(user_input)\n",
        "  print(context)\n",
        "  assert context is not None\n",
        "  assert len(context) > 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "g9Hv-lwf20Up",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9Hv-lwf20Up",
        "outputId": "d5bab29e-4dc7-45a5-8b54-7a0bce02e4f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                                                                       [100%]\u001b[0m\n",
            "\u001b[33m========================================= warnings summary =========================================\u001b[0m\n",
            "../usr/local/lib/python3.12/dist-packages/_pytest/config/__init__.py:1290\n",
            "  /usr/local/lib/python3.12/dist-packages/_pytest/config/__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; anyio\n",
            "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
            "\n",
            "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
            "============================================== PASSES ==============================================\n",
            "\u001b[32m\u001b[1m___________________________________________ test_geo_api ___________________________________________\u001b[0m\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "jenue: 58.30049329999999, -134.4201306\n",
            "Anchorage: 61.2175758, -149.8996785\n",
            "Fairbanks: 64.8400511, -147.7199756\n",
            "\u001b[32m\u001b[1m_____________________________________ test_get_points_metadata _____________________________________\u001b[0m\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "AER 143 236\n",
            "\u001b[32m\u001b[1m___________________________________ test_get_points_metadata_bad ___________________________________\u001b[0m\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "AFG 384 76\n",
            "\u001b[32m\u001b[1m________________________________________ test_get_forecast _________________________________________\u001b[0m\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "61.2175758 -149.8996785\n",
            "This Afternoon\n",
            "Slight Chance Light Rain\n",
            "A slight chance of rain. Mostly cloudy, with a high near 34. Northeast wind around 5 mph. Chance of precipitation is 20%.\n",
            "\u001b[32m\u001b[1m__________________________________________ test_rag_query __________________________________________\u001b[0m\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "How do I become a snowplow driver with ADS?\n",
            "Check job postings for equipment operator or driver positions. Applicants typically need a commercial driver’s license (CDL) and relevant experience.\n",
            "--------------------\n",
            "Does ADS offer financial assistance for snow removal equipment?\n",
            "ADS does not provide direct financial assistance. However, some state grants may be available to local governments for purchasing snow removal equipment.\n",
            "--------------------\n",
            "What training do ADS snowplow drivers receive?\n",
            "Drivers undergo specialized training in winter driving techniques, equipment maintenance, and safety protocols for extreme cold environments.\n",
            "--------------------\n",
            "What is the process for requesting a snow berm removal?\n",
            "A berm is the leftover snow pile created by plows. Contact your local ADS district; they may clear excessively large berms if they pose a safety risk.\n",
            "--------------------\n",
            "What is the mission of the Alaska Department of Snow?\n",
            "Our mission is to ensure safe, efficient travel and infrastructure continuity by coordinating snow removal services across the state’s 650,000 square miles.\n",
            "--------------------\n",
            "\n",
            "\u001b[33m\u001b[32m6 passed\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 3.71s\u001b[0m\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<ExitCode.OK: 0>"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ipytest.run('-rP')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6F_yiYuUNfzG",
      "metadata": {
        "id": "6F_yiYuUNfzG"
      },
      "source": [
        "### Evaluation Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_rhFbxhM_AE8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "_rhFbxhM_AE8",
        "outputId": "6769e9ae-b661-4e88-a0b3-4f7e1a2ab6a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:vertexai.evaluation._evaluation:Generating a total of 7 responses from the custom model function.\n",
            "100%|██████████| 7/7 [00:02<00:00,  3.40it/s]\n",
            "INFO:vertexai.evaluation._evaluation:All 7 responses are successfully generated from the custom model function.\n",
            "INFO:vertexai.evaluation._evaluation:Multithreaded Batch Inference took: 2.067320701000426 seconds.\n",
            "INFO:vertexai.evaluation._evaluation:Computing metrics with a total of 7 Vertex Gen AI Evaluation Service API requests.\n",
            "100%|██████████| 7/7 [00:22<00:00,  3.17s/it]\n",
            "INFO:vertexai.evaluation._evaluation:All 7 metric requests are successfully computed.\n",
            "INFO:vertexai.evaluation._evaluation:Evaluation Took:22.20780835700134 seconds\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-ed4ff427-eeaf-46a6-99a0-5d332782e953\" href=\"#view-view-vertex-resource-ed4ff427-eeaf-46a6-99a0-5d332782e953\">\n",
              "          <span class=\"material-icons view-vertex-icon\">bar_chart</span>\n",
              "          <span>View evaluation results</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-ed4ff427-eeaf-46a6-99a0-5d332782e953');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation');\n",
              "              } else {\n",
              "                window.open('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "row_count 7\n",
            "groundedness/mean 0.14285714285714285\n",
            "groundedness/std 0.37796447300922725\n",
            "                                              prompt  \\\n",
            "0                              What is your mission?   \n",
            "1          What is the weather in fairbanks tonight?   \n",
            "2                           what does ADS stand for?   \n",
            "3  How does the DOT&PF prioritize snow removal on...   \n",
            "4  How does the department address environmental ...   \n",
            "5            Are there any weather alerts for Stika?   \n",
            "6                how to handle avalanche emergancies   \n",
            "\n",
            "                                            response  \\\n",
            "0  I am a large language model, trained by Google...   \n",
            "1  Tonight in Fairbanks, it will be mostly clear ...   \n",
            "2  I'm sorry, I still cannot tell you what \"ADS\" ...   \n",
            "3  As previously stated, the information availabl...   \n",
            "4  I am sorry, but I still cannot find any inform...   \n",
            "5  I can only check weather forecasts for valid c...   \n",
            "6  I'm sorry, I still do not have information on ...   \n",
            "\n",
            "                            groundedness/explanation  groundedness/score  \n",
            "0  The response provides information about the AI...                 0.0  \n",
            "1  The user prompt only asks a question and does ...                 0.0  \n",
            "2  The response includes information about the AI...                 0.0  \n",
            "3  The response introduces an entity 'ADS (Alaska...                 0.0  \n",
            "4  The AI response accurately states that the nec...                 1.0  \n",
            "5  The response introduces external information n...                 0.0  \n",
            "6  The response mentions 'The previous context on...                 0.0  \n"
          ]
        }
      ],
      "source": [
        "prompt_list = [\n",
        "    \"What is your mission?\",\n",
        "    \"What is the weather in fairbanks tonight?\",\n",
        "    \"what does ADS stand for?\",\n",
        "    \"How does the DOT&PF prioritize snow removal on state roads and airports?\",\n",
        "    \"How does the department address environmental concerns related to the use of de-icing chemicals and sand?\",\n",
        "    \"Are there any weather alerts for Stika?\",\n",
        "    \"how to handle avalanche emergancies\",\n",
        "]\n",
        "eval_dataset = pd.DataFrame({\n",
        "    \"prompt\": prompt_list,\n",
        "})\n",
        "\n",
        "#Instantiate an EvalTask by associating your dataset & selected metric\n",
        "eval_task = EvalTask(\n",
        "  dataset=eval_dataset,\n",
        "  metrics=[MetricPromptTemplateExamples.Pointwise.GROUNDEDNESS], # optionally also check quesiton answering\n",
        ")\n",
        "\n",
        "evalresults = eval_task.evaluate(\n",
        "      model=generate,\n",
        ")\n",
        "\n",
        "# Print the results\n",
        "for row in evalresults.summary_metrics:\n",
        "  print(f\"{row} {evalresults.summary_metrics[row]}\")\n",
        "\n",
        "print(evalresults.metrics_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E5zGQCeSTyG1",
      "metadata": {
        "id": "E5zGQCeSTyG1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "lab5_save_model_armor.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
